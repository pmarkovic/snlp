{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xwZKbE3vFwP"
   },
   "source": [
    "# Assignment 9\n",
    "\n",
    "Name 1: Rricha Jalota <br/>\n",
    "Id 2: 7010592 <br/>\n",
    "Email id 1: rrja00001 <br/>\n",
    "\n",
    "Name 2: Pavle Markovic <br/>\n",
    "Id 2: 7007913 <br/>\n",
    "Email id 2: pama00002 <br/>\n",
    "\n",
    "**Instructions:** Read each question carefully. <br/>\n",
    "Make sure you appropriately comment your code wherever required. Your final submission should contain the completed Notebook and the Python files. There is no need to submit the data files. <br/>\n",
    "Upload the zipped folder in Teams. Make sure to click on \"Turn-in\" after your upload your submission, otherwise the assignment will not be considered as submitted. Only one from the group should make the submisssion.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2v6OVU_HvH9k"
   },
   "source": [
    "# Exercise 1: Text Classification (10 points)\n",
    "\n",
    "Based on your implementation of the `Corpus` and `Document` classes from the previous assignment, you will now build a simple Naive Bayes classifier to classify each document in the test section of the Reuters News corpus. \n",
    "\n",
    "We will use the TF-IDF metric as the feature for our classifier. TF-IDF of a term $t$ in a document $d$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\text{TF-IDF}(t,d) = \\frac{\n",
    "    \\text{TF}(t,d)\n",
    "  }{\n",
    "    \\text{IDF}(t)\n",
    "  }\n",
    "\\end{equation}\n",
    "\n",
    "with $\\text{TF}(t,d)$ being the defined as\n",
    "\n",
    "\\begin{equation}\n",
    "  \\text{TF}(t,d) = \\frac{\n",
    "    f_{t,d}\n",
    "  }{\n",
    "    \\sum_{t'} f_{t',d}\n",
    "  }\n",
    "\\end{equation}\n",
    "\n",
    "where $f_{t,d}$ is the absolute frequency of term $t$ in document $d$.\n",
    "\n",
    "and $\\text{IDF}(t)$ being defined as \n",
    "\n",
    "\\begin{equation}\n",
    "  \\text{IDF}(t) = \\frac{\n",
    "    N\n",
    "  }{\n",
    "    |\\{d \\in D: C_d(t) > 0\\}|\n",
    "  }\n",
    "\\end{equation}\n",
    "\n",
    "where $D$ stands for the documents in the corpus, $N=|D|$ and $C_d(t)$ is the number of times term $t$ occurs in document $d$.\n",
    "\n",
    "In a TF-IDF matrix, documents are represented by the rows of the matrix and TF-IDF features by its columns. This means that each row vector consists of the TF-IDF value for a term taken from a fixed, shared vocabulary given the document, i. e. $\\text{TF-IDF}(t,d)$, for $t \\in V$ ([this](https://www.researchgate.net/profile/Maryam-Hourali/publication/306358542/figure/tbl1/AS:648973966651395@1531738859631/Some-Part-of-TF-IDF-Term-Document-Matrix.png) is a small example). \n",
    "\n",
    "## 1.1 Vocabulary as feature space (2 points)\n",
    "\n",
    "Construct a shared vocabulary $V$ for the Reuters corpus, using both the train set and the test set. You are expected to reduce the size of the vocabulary by \n",
    "  * Preprocessing (removing punctuation, lowercasing, tokenizing). (0.25 points)\n",
    "  * Lemmatizing the tokenized text. (0.5 points)\n",
    "  * Setting a $\\text{min_df}$ and $\\text{max_df}$ and removing all terms from the vocabulary that occur in less then $\\text{min_df}$ and more than $\\text{max_df}$ documents. You should support your choice with a source from the internet or your own reasoning. (0.5 point)\n",
    "  * Why is it necessary to reduce the size of the vocabulary and to set a lower and upper bound to document frequency? Explain in 2-3 sentences. (0.25 points)\n",
    "\n",
    "You are allowed to use any Python package useful to the task. We suggest using NLTK's [RegexpTokenizer](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.regexp.RegexpTokenizer) for tokenization and [WordNetLemmatizer](https://www.nltk.org/api/nltk.stem.html#nltk.stem.wordnet.WordNetLemmatizer) for lemmatization. The implementation should be in the `reduce_vocabulary` method of the `Corpus` class. Check that your implementation is correct by executing the code cell below and comparing vocabulary sizes before and after the reduction. \n",
    "  \n",
    "As always, you are free to define new methods as you need them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "* It is important to reduce the vocabulary size in order to preserve only words that provide valuable information for the task. Words that appear in many or all documents are not helpful for distinguishing between different document categories. On the other hand, words that appear only in a few documents (e.g. 1 or 2) are probably not representative features of that document category. Lastly, due to computational limitations, it might be required to reduce the vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8sYqeIW08JZg"
   },
   "outputs": [],
   "source": [
    "# Data loading\n",
    "from nltk.corpus import reuters, stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/rrichajalota/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/rrichajalota/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FvJYIFZM6LQg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Reuters corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10788/10788 [00:15<00:00, 697.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocab size before reduction: 28370\n",
      "\n",
      "Vocab size after reduction: 8783\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import exercise_1\n",
    "exercise_1 = reload(exercise_1)\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Loading Reuters corpus...\")\n",
    "corpus = exercise_1.Corpus(\n",
    "    documents=[\n",
    "    exercise_1.Document(fileid, reuters.raw(fileid), reuters.categories(fileid), stop_words=stop_words) \n",
    "    for fileid in tqdm(reuters.fileids())],\n",
    "    categories=reuters.categories()\n",
    ")\n",
    "print(\"\\nVocab size before reduction:\", len(corpus.terms()))\n",
    "\n",
    "# set min_df, max_df\n",
    "min_df = 5\n",
    "max_df = 0.7\n",
    "# As per this reddit forum https://www.reddit.com/r/learnmachinelearning/comments/6evguc/while_building_a_tfidf_determining_a_good_balance/,\n",
    "# it is advised to use an integer value between 5-10 as min_df and a percent value as the maximum. There is no thumb rule\n",
    "# for setting the max_df value and one must experiment with the corpus to find the best suited value. \n",
    "\n",
    "reduced_vocab = corpus.reduce_vocab(min_df=min_df, max_df=max_df)\n",
    "\n",
    "print(\"\\nVocab size after reduction:\", len(reduced_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6ztKAsZ-HTV"
   },
   "source": [
    "## 1.2 TF-IDF matrix (2 points)\n",
    "\n",
    "1. Implement the method `_idfs` of the `Corpus` class. It should take the reduced vocabulary as input and return a dictionary containing the IDFs of each word in the reduced vocabulary. Print the IDFs of the first 10 terms (sorted lexicographically) from the reduced vocabulary. Store the IDFs in a class variable `idfs`. Why is it a good idea to calculate IDFs first? (1 points)\n",
    "\n",
    "2. Implement the method `_tfs_idfs` of the corpus class. It should return a vector or a a list containing the TF-IDFs of all terms in the reduced vocabulary for a single document. It should use the `_idfs` method once internally. (1 point)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer \n",
    "1. Since IDF is calculated for each term of the shared vocabulary (common vocab among all documents), for computational efficieny, we dont need to calculate idf for each term, while we calculate tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_gqWAqjjvFD-",
    "outputId": "b7be5b09-6cea-4498-fbab-a14c64434ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating idfs\n",
      "0 2.0947603542232414\n",
      "00 3.9486516045583024\n",
      "000 1.2659192114403823\n",
      "0000 6.88829441146125\n",
      "001 6.241667246536197\n",
      "002 6.395817926363456\n",
      "003 6.647132354644362\n",
      "004 6.721240326798084\n",
      "005 6.452976340203405\n",
      "006 6.513600962019839\n"
     ]
    }
   ],
   "source": [
    "# TODO: load and print IDFs!\n",
    "idfs = corpus._idfs(reduced_vocab)\n",
    "print(\"Estimating idfs\")\n",
    "for term in reduced_vocab[:10]:\n",
    "  print(term, idfs[term])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9z7TVYQyAgNW"
   },
   "source": [
    "## 1.3 Train/test split (1.5 points)\n",
    "\n",
    "1. Implement the method `_category2index`. It should take a string (the name of the category) as input and return its index in the `Corpus`-internal list of categories. (0.25 points)\n",
    "2. Implement the method `compile_dataset` of the `Corpus` class. It should take the reduced vocabulary as input and return two tuples: (train TF-IDF matrix, train labels) and (test TF-IDF matrix, test labels). The train matrix/labels should be derived from the train section of the Reuters dataset (file-ids starting with `training/`) and the test matrix/labels from the test section (file-ids starting with `test/`).\n",
    "\n",
    "  Make use of the methods `_tf_idfs` and `_category2index` (1 point)\n",
    "\n",
    "3. Use the method `compile_dataset` to load the train and test data into variables. Please name the variables such that we can distinguish the train data from the test data. Show the size of the train and test set. (0.25 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Dv0gDKDWC2Dp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7769 3019\n"
     ]
    }
   ],
   "source": [
    "# TODO: load train and test data\n",
    "(X_train, Y_train), (X_test, Y_test) = corpus.compile_dataset(reduced_vocab)\n",
    "\n",
    "# Show size of train and test set\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SC4liSllDOVQ"
   },
   "source": [
    "## 1.4: Naive Bayes Classifier (5 points)\n",
    "\n",
    "A Naive Bayes classifier assigns a datapoint $x = x_1,...x_n$ to a class $C_k$ ($1 \\leq k \\leq K$, with $K$ being the number of classes) with probability $P(C_k|x)$ given by:\n",
    "\n",
    "\\begin{equation}\n",
    "  p(C_k|x) = \\frac{\n",
    "    p(C_k)p(x|C_k)\n",
    "  }{\n",
    "    p(x)\n",
    "  }\n",
    "\\end{equation}\n",
    "\n",
    "1.  Describe the idea behind Naive Bayes in 3-4 sentences. Do so by explaining the terms 'naive' and 'Bayes(ian)' (1 point)\n",
    "2. For each part of the above formula, assign it to one of the following categories, and give a short explanation. (1 point)\n",
    "  * Prior\n",
    "  * Posterior\n",
    "  * Likelihood\n",
    "  * Evidence\n",
    "\n",
    "3. In our dataset from 1.3, what corresponds to $C_k$? What to $x$? (0.5 points)\n",
    "\n",
    "4. What is a good baseline for estimating the accuracy of our classifier? How would you evaluate it? Explain in 1-2 sentences **and** support your answer with code. This will also help you check the accuracy you get on the actual data. (1 point)\n",
    "\n",
    "5. Train a Naive Bayes classifier on the train section of our dataset and report precision, accuracy and F-score on the test section. You may use the class [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) and the method [precision_recall_fscore](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html) from the [scikit-learn](https://scikit-learn.org/stable/install.html) Python package. You can write the code in the code cell below. (2 points)\n",
    "  \n",
    "6. Do you observe a difference in the F-scores of different classes? Why? What could you do to account for your finding? (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers\n",
    "1. Naive Bayes is collection of algorithms based on Bayes Theorem which assume that all features are independent of each other and they contribute equally to classification. Bayesian approach is a probabilistic approach for updating a prior belief for values given that some event happend. Naive part comes from independence assumption which allows for transforming the formula $P(C_k|x) = \\frac{P(C_k)P(x|C_k)}{P(x)}$ to $P(C_k|x) = \\frac{P(C_k)P(x_1|C_k)P(x_2|C_k)...P(x_n|C_k)}{P(x_1)P(x_2)...P(x_n)}$. Finally, since $P(x_1)P(x_2)...P(x_n)$ is constant over training and different classes, it can be omitted, and leaving the final simplified formula $P(C_k|x) = P(C_k) \\prod_{i=1}^n{P(x_i|C_k)}$.  \n",
    "\n",
    "2. Parts of the formula:\n",
    "Prior - $P(C_k)$ -> It is initial belief for the value of interest.  \n",
    "Posterior - $P(C_k|x)$ -> It is updated belief for the value of interest given that some event happend.  \n",
    "Likelihood - $P(x|C_k)$ -> It is probability that some event will happen given the value of interest.  \n",
    "Evidence - $P(x)$ -> It is probability that some event that cause update of the value of interest happend.  \n",
    "\n",
    "3. $C_k$ is $k^{th}$ category of all posible for documents classification, while $x$ is feature vectors, i.e. reduced vocabulary.  \n",
    "\n",
    "4. Decision Tree classifier would be a good baseline because we can provide it the entire dataset with all features and it learns simple decision rules (a tree hierarchy based on feature information gain/entropy, etc.) by inferring from training data. We can evaluate it using precision, recall, F-measure and accuracy metrics. \n",
    "\n",
    "6. Yes, there is a difference in the F-scores. Because while decision tree considers the relationship between features, naive bayes classifier completely ignores it. Since the features are not independent of each other, decision tree gives a better performance than NB classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/rrichajalota/.local/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.19.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OVMp0gIzIi0H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 0.7830407419675389\n",
      "baseline precision, recall, fscore: (0.4082732723961839, 0.33706436753181646, 0.3511497760931471, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB accuracy: 0.6382908247764161\n",
      "NB precision, recall, fscore: (0.3338856294672092, 0.19654734736391868, 0.2261739698422157, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Find accuracy of baseline classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(f\"baseline accuracy: {accuracy_score(Y_test, pred)}\")\n",
    "print(f\"baseline precision, recall, fscore: {precision_recall_fscore_support(Y_test, pred, average='macro')}\")\n",
    "\n",
    "# train classifier, report precision, recall, fscore\n",
    "clf2 = GaussianNB()\n",
    "clf2 = clf2.fit(X_train, Y_train)\n",
    "pred = clf2.predict(X_test)\n",
    "print(f\"NB accuracy: {accuracy_score(Y_test, pred)}\")\n",
    "print(f\"NB precision, recall, fscore: {precision_recall_fscore_support(Y_test, pred, average='macro')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StlojTryeIdd"
   },
   "source": [
    "## Bonus: Support Vector Machines (1.5 points)\n",
    "\n",
    "Consider the task of Named Entity Recognition. In a simplified scenario, you want to decide for each word if it belongs to one of the following classes: {not-named-entity, person, city, country, currency}. An expert in the field tells you that you should start with the following set of features:\n",
    "- is the whole word in capitals\n",
    "- is the first letter capitalized\n",
    "- does it begin a sentence\n",
    "- number of characters \n",
    "- is a stopword\n",
    "- number of Wikipedia articles that contain this word in their title\n",
    "\n",
    "1. Come up with at least 3 more features for this problem. (0.2 points)\n",
    "2. How can we numerically represent each datapoint? What is the mathematical object called and what is the set in which it lives? (0.2 points)\n",
    "3. What is a hyperplane and how can it be used in this context? (0.2 points)\n",
    "4. Imagine that you've been given two features: $f_1, f_2$ and the following dataset. The task is currently only to distinguish between two classes. Draw the points and 3 hyperplanes:\n",
    "  - one that mispredicts at least one datapoint\n",
    "  - one that predicts everything correctly\n",
    "  - one that predicts everything correctly but is in some sense worse than the previous one\n",
    "\n",
    "|Data point|$f_1$|$f_2$|class|\n",
    "|---|---|---|---|\n",
    "|$d_1$|2|2|Y|\n",
    "|$d_2$|10|9|Y|\n",
    "|$d_3$|2|5|Y|\n",
    "|$d_4$|3|5|Y|\n",
    "|$d_5$|2|-2|N|\n",
    "|$d_6$|10|0|N|\n",
    "|$d_7$|10|-4|N|\n",
    "|$d_8$|3|3|N|\n",
    "\n",
    "  In all cases provide the formula for the hyperplane and explain how to use it to make a decision regarding which class it belongs to. (0.65 points)\n",
    "\n",
    "5. In the previous question, you created hyperplanes that helped you in determining which of the two classes the datapoint belongs to. How would you extend this to solve the original problem, i.e. predicting which of the 5 classes the datapoint belongs to? (0.25 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TH0UZYLl2Tp2",
    "K6a2UUP09Mh0"
   ],
   "name": "Assignment9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
